{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages for crawler\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import requests\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "#import packages for the CNN\n",
    "from keras.models import model_from_json\n",
    "import CNN\n",
    "import twitter_crawler_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beg daddy twitter for a scrap of data.\n",
    "\n",
    "consumer_key = 'KvuDZafQCvKBV6LOkPWMPOfEp'\n",
    "consumer_secret = '9SZbcgI4kM6ZLkidT5GFK5mf3HS8Pq44bvUn8HlFjomxAsIQj2'\n",
    "access_token = '1282737152233820162-R1qmQtiPcvw89KOpKx9w1JqbvX1g3c'\n",
    "access_secret = 'fXR6ip6c1T7TjuQdImsMJbWZ4dvOn8VHBK4cp4njZMoIg'\n",
    " \n",
    "@classmethod\n",
    "def parse(cls, api, raw):\n",
    "    status = cls.first_parse(api, raw)\n",
    "    setattr(status, 'json', json.dumps(raw))\n",
    "    return status\n",
    " \n",
    "# Status() is the data model for a tweet\n",
    "tweepy.models.Status.first_parse = tweepy.models.Status.parse\n",
    "tweepy.models.Status.parse = parse\n",
    "# User() is the data model for a user profil\n",
    "tweepy.models.User.first_parse = tweepy.models.User.parse\n",
    "tweepy.models.User.parse = parse\n",
    "# You need to do it for all the models you need\n",
    " \n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    " \n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "\n",
    "#username = input(\"Input the username associated with your twitter account: \")\n",
    "username = 'megancarrots0'\n",
    "\n",
    "#get tweets\n",
    "tweet_id = twitter_crawler_api.get_img(api,username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class/index info for classification\n",
    "#path\n",
    "data_path = os.path.join('twitter_images','*g')\n",
    "# load json and create model\n",
    "json_file = open('model_2.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"model_2.h5\")\n",
    "loaded_model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process images, do linear algebra, make cat dir.\n",
    "data = CNN.process_images(data_path)\n",
    "is_cat = CNN.final_answer(data,loaded_model)\n",
    "twitter_crawler_api.get_cats(is_cat,tweet_id,api)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
